:PROPERTIES:
:ID:       63d4a8c6-f142-47e1-9865-9db05b18a3ea
:END:
#+title: Metropolis-Hastings
#+startup: latexpreview inlineimages
#+filetags: :Bayes:

Metropolis Hastings method is a [[id:b055093c-ed5e-4e0e-b285-458744821241][MCMC]] method based on random walks, which is the basis of many more [[id:4c2833a0-5351-4fba-b25e-4985acbd205f][Sampling methods]].


It relies on the knowledge of a target pdf, known up to a normalising constant, as it is often the case in [[id:8dcedd6a-85dc-4af5-afde-5936cef961d6][Bayesian Inference]]



* Python example

#+begin_src python :session
import numpy as np
import matplotlib.pyplot as plt
#+end_src

#+RESULTS:

#+begin_src python :session
def p(x):
    return 0.3 * np.exp(-0.2 * x**2) + 0.7 * np.exp(-np.sqrt((x-7)**2))

def q_sample(xprime, sigma=1):
    return np.random.normal(xprime, 1, size=1)

def q_pdf(x, xprime, sigma=1):
    return np.exp(-(x-xprime)**2 / (2 * sigma**2)) / np.sqrt(2 * np.pi * sigma)
#+end_src

#+RESULTS:


#+begin_src python :session
def Metropolis_Hastings(x0, p, q_sample, q_pdf, sigma, N):
    x = np.empty(N + 1)
    x[0] = x0
    for i in range(N):
        candidate = q_sample(x[i], sigma)
        A = p(candidate) * q_pdf(candidate, x[i]) / (p(x[i]) * q_pdf(x[i], candidate))
        print(A)
        if np.random.uniform() < A:
            x[i + 1] = candidate
        else:
            x[i + 1] = x[i]
    return x
#+end_src

#+RESULTS:

#+begin_src python :session :results file
x_samples = Metropolis_Hastings(x0=0, p=p, q_sample=q_sample, q_pdf=q_pdf, sigma=0.5, N=10000)
plt.figure(figsize=(4, 4))
plt.hist(x_samples, density=True)
x_ls = np.linspace(-5, 10, 200)
dx = x_ls[1] - x_ls[0]
plt.plot(x_ls, p(x_ls)/ (np.sum(p(x_ls)) * dx))
fname='/home/victor/org-roam/images/MH.png'
plt.savefig(fname)
plt.close()
fname
#+end_src

#+RESULTS:
[[file:/home/victor/org-roam/images/MH.png]]
