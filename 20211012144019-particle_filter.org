:PROPERTIES:
:ID:       9da81fb6-71ba-458c-85d0-d8c5c840faf5
:END:
#+title: Particle Filter
#+STARTUP: latexpreview

The particle filter is a [[id:4c2833a0-5351-4fba-b25e-4985acbd205f][Sampling method]] adapted for non-linear dynmamics
* Particle Filtering
** State space model

 * Let $X_0,\dots$ be a [[id:463a3501-d30d-4a4d-81b3-664ee6a2063e][Markov Chain]] on $\mathbb{R}^d$, with
   transition probability $p(x_k \mid x_{k-1})$, and initial state
   $p(x_0)$.
 * Let $Y_0, \dots$ be the observations, such that $p(y_k \mid x_k)$

** Particle Approximation

The full distribution is approximated using a set of weighted
 particles $\{(w_k^L, x_k^L) \mid 1\leq L \leq P\}$
 giving the approximation
\begin{equation}
p(x_0,\dots,x_k \mid y_1,\dots, y_k) \approx \sum_{i=1}^P w_k^i \delta_{x_k^i}(x_k)
\end{equation}
where $\delta$ is the Dirac delta
   
** Sampling Importance Resampling

[[id:5067b3e2-838b-4ca6-a765-a28fc640fd29][Sampling Importance Resampling]] can be used to determine the weights.
Let $q(x_0 \dots x_k \mid y_1 \dots y_k)$ be a distribution from which
we sample $(x^i_{0},\dots x^i_{k})$.
The weights are defined by
\begin{equation}
w^i_k = \frac{\tilde{w}^{i}_k}{\sum_{j=1}^P\tilde{w}^j_k}
\end{equation}
where
\begin{equation}
\tilde{w}^i_k = \frac{p(x^i_0, \dots x^i_k \mid y_1, \dots, y_k)}{q(x^i_0, \dots x^i_k \mid y_1, \dots, y_k)}
\end{equation}


* Sequential algorithm
Let us assume that the approximation of $p(x_0,\dots x_{k-1} \mid y_1,
\dots y_{k-1})$ is known. How to approximate $p(x_0,\dots x_{k} \mid
y_1, \dots y_{k})$ ?
** Sampling
We make the following assumption:
\begin{equation}
q(x_0, \dots, x_k \mid y_1 \dots, y_k) = q(x_k \mid x_0,\dots,x_{k-1}, y_1, \dots y_{k}) \cdot q(x_{0},\dots,x_{k-1} \mid y_1, \dots y_{{k-1}})
\end{equation}

So given existing samples $(x^i_{0}, \dots x^i_{k-1})\sim q(x_{0},\dots,x_{k-1} \mid y_1, \dots y_{{k-1}})$,
we can draw a new state $x_k^i \sim q(x_k \mid x_0,\dots,x_{k-1}, y_1, \dots y_{k})$.
** Importance weights
The weights are then updated accordingly as the new measurement becomes available:

\begin{equation}
  w_k^i \propto w_{k-1}^i \frac{p(y_k \mid x_k^i)p(x_k^i \mid x_{k-1}^i)}{q(x_k^i \mid x_{0}^i,\dots x_{k-1}^i, y_1,\dots y_k)}
\end{equation}
and rennormalized
** Resampling
Over time, the weight variance increases, meaning that the number of
significant particles decreases, as it will concentrate in regions of
high probability.
A resampling step is thus necessary from time to time.
The Effective Sample Size (ESS) is then often used in order to decide on a resampling step:
\begin{equation}
\mathrm{ESS} = \frac{\sharp \text{ of particles}}{\sum \left(w_k^i\right)^2}
\end{equation}
If below a specified threshold, we generate $N$ new particles among
$(x_{0}^i, \dots, x_k^i)$ depending on their probabilities given by
the weights $(w_k^i)$. Afterwards, set all weights to $1/ N$.
