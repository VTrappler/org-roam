:PROPERTIES:
:ID:       f867396d-b033-4fa7-b99a-b4dd551ae37b
:ROAM_ALIASES: TLM Backpropagation
:END:
#+title: Adjoint Method
#+STARTUP: latexpreview



* Tangent Linear Model
** Linear approximation
Let us consider a function $f$, derivable at a point $a$.
The linear approximation of $f$ around $a$ is
\begin{align}
f(x) &= f(a) + f'(a)(x-a)Â + o(x-a)\\
f(a + h) &= f(a) + f'(x)h + o(h)
\end{align}

In terms of increments, we write
$\delta f = f(a+h) - f(a)$, and $\delta x = h$, so the approximation becomes
\begin{equation}
\delta f = f'(x) \delta x
\end{equation}


A review on the adjoint method can be found in
cite:plessix_review_2006, but also in cite:kumar_adjoint_nodate

* Perturbation theory
Let us define a function
\begin{equation}
x \mapsto J(x)= h(u(x), x)
\end{equation}
The state variable $x$ satisfy the state equation $F(u(x), x)=0$
 * $F$ is called the forward equation
 * A state variable $u$ is an "admissible" state vector and is a
   *physical* realization if $\exists x$ such that $F(u, x)=0$
 * 

* Lagrangian based

Another "proof" is based on the [[id:713b6a9f-24f1-4bf2-9dd9-92af579c3a35][Lagrangian]].
